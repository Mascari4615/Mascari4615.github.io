---
title: "🌑 AI, 로봇 실습 과목"
date: 2023-09-06. 15:06
# last_modified_at: 2023-09-06. 15:06
# last_modified_at: 2023-09-12. 10:15
# last_modified_at: 2023-09-13. 15:01
# last_modified_at: 2023-09-19. 09:58
# last_modified_at: 2023-09-20. 15:09
last_modified_at: 2023-09-26. 10:01
categories: ⭐Computer 🌑Computer-General
---

@ 화 315  
@ 수 201  

### 💫 머신러닝 VS 딥러닝

---

머신러닝  
Input -> 특징 추출 -> 분류, 회귀 -> Output  
인공신경망 없이 Classification 분류나 Regression 회귀하는  

Feature Extraction 특징 추출 이후에서야 분류, 회귀가 가능  
-> 때문에 Domain Knowledge 전문 지식이 딥러닝보다 상대적으로 더 요구됨  

딥러닝  
Input -> 특징 추출 + 분류 회귀 -> Output  
인공신경망을 이용한 수치 해석  
인공신경망 내부에서 (자체에서) 분류, 회귀가 가능  

머신러닝보다 상대적으로 좀 더 복잡한 모델  
-> 복잡한 데이터(양, 차원적으로)를 다룰 때, 머신러닝보다 상대적으로 더 정확한 모델을 생성할 가능성이 높음  

인공신경망을 구성할 때 계산되는 Parameter가 굉장히 많고, 결정해야하는 Hyper Parameter가 많기 때문에  
데이터, 모델 사이즈가 클 수록 딥러닝이 더 잘 맞는 경우가 많음  

### 💫 머신러닝, 딥러닝의 세 타입

---

회귀 - 앞으로 어떻게 되나?  

Supervised 지도학습  
Input, Output을 주고 분류, 회귀  

Unsupervised 비지도학습  
Input만 주는  
미지수 2개, 방정식 1개 = 풀 수 없는 문제  
Clustering 군집화  

Reinforcement 강화학습  
Agent가 Action을 Environment에 취했을 때 Reword를 주는..?  

### 💫 머신러닝, 딥러닝

---

Distribution 확률분포가 유사한 데이터를 학습해야한다  

전통적인 방법 : 규칙 만들고 고치고  
그래서 전문 지식이 있어야 하는  

머신러닝 방법 : 지혼자 계속 최적화하는  
데이터만 잘 볼 수 있다면, 전문 지식 없이도  

### 💫 머신러닝

---

KNN Classifier  
K Nearest Neighbors  
근처 K 개의 이웃을 가지고, 내가 누구인지  
때문에 K는 홀수로  
복잡한 디멘션 느리다  

Decision Tree  
알고리즘 성능 측정에 좋다  
데이터를 분개해서 Entropy 복잡도가 가장 낮은 정도의 데이터까지 가도록  
이후 분류, 회귀  
많이 모이면 Random Forest  

Support Vector Machine SVM  
데이터를 분류하는 선 Hyper Line, Hyper Plane  
분류 별로 가장 Hyper Line, Hyper Plane과 가까운 요소와의 거리가 최대가 되도록  
Hyper Line, Hyper Plane을 만드는 Kernel Function -> 어려움  
Cost Function, Object Function, 목적 함수를 만들때는 이정도만 이해해도  

### 💫 딥러닝

---

인공신경망, 체내 신경망을 수학적으로 표시한  
뉴런 -> Node  
Input Layer, Hidden Layer, Output Layer

내가 가지고 있는 데이터에 대해서만 적합한, Overfitting 문제 주의  

Activation Function 활성함수  
자극 받았, 임계치 값 이상을 넘겨주는 역할  
계단식 함수, 0 ~ 1 시그모이드 함수, 렐유 함수 (오버피팅 방지)  

Linear한 알고리즘을 좀 더 Non Linear하게 복잡하게 만들어주는  

### 💫 1차시

---

[Nature of Code](https://natureofcode.com/book/introduction/)  
지능? 뭔지 말할 수는 없지만 느낌은 알고 있다  

### 💫 2차시

---

기호주의 VS 연결주의  
머신러닝 VS 딥러닝  

강인공지능, Strong AI,  
인간 수준의 지능  

인공일반지능, A General I, AGI  
다양한 문제를 해결하고 다향한 지능적 활동을 수핼할 수 있는 능력  
강인공지능, 약인공지능 사이

약인공지능, Weak AI, Narrow AI  
특정한 작업/도메인에서 인간과 유사한 성능을 발휘하는  

튜링 테스트  
Imitation/모방 Game  

에 대한 반박  
중국어방  

에 대한 반박  
System Response  

@ 비욘드 EBS 지능 만들기  

### 💫 3차시

---

AI Application Programming  

Brief 요약  
Manner 방식  
Exhibiting  
Characteristics 특징  
Fraud 사기  
Investigate 조사  

퍼지 추론  
I.E. 카메라 초점  

Lisp -> Python?  

NP-complete  

Simulated Annealing, 모의 담금질 (유사 담금질)  
최적화 -> 검색 -> 모의 담금질  

담금질 : 금속을 가열하고 급냉시켜 경도를 높히는 작업  

고체 -> 액체 -> 기체  
고체 <- 액체 <- 기체  

안정 -> 불안정 (변화 가능한)  

지금보다 더 나은 상태를 요구  
지금 그대로가 아니라 변화가 있어야  
변화가 일어나기 쉬운 상태로  
계속해서 변화만 하면 안됨, 다시 안정한 상태로 만듦  

맹목적 알고리듬  
Greedy Algorithm  
Hill Climbing Algorithm  

임의의 조건/가중치 계산, 결과 저장  
임의의 변형, 새로운 결과 저장  
이전 결과와 새로운 결과 비교  

이를 반복하여 답을 찾는 것 (지금보다 좋은 상황만 찾음)  
-> Greedy Algorithm  

지금 상태가 정말 가장 좋은 상태인가?  
Local M, Global M  

현재 위치에서 한 발자국 씩 옮겨서 더 높은 곳으로 이동  
-> Hill Climbing Algorithm  

평면이나 Local M을 만난다면?  
Local M, Global M  
과적합?  
여러 군데에서 시작하는?  

제일 좋은 곳을 가기위해서는  
좋은 곳만 찾아가지 말고  
욕심을 버리고 아래로 내려가야 한다  
-> 정착을 못함  

시간이 지날수록 조건을 까다롭게  

N Queens  
N x N 보드에서, 서로 영향을 줄 수 없는 체스 여왕 배치 경우의 수  

### 💫 4차시

---

@ 강의실 어딘지 너무 헷갈려~  

초기 soln를 대충 만들어두고  
soln를 평가  
답(최정상)은 모르니까 대강 어느정도 좋다  

핵심 두 가지  

1. 지금보다 더 좋지 않은 솔루션을 찾은 경우에도 이전 것을 버리고 나쁜 것을 받아들일 수 있다는 것
2. 나쁜 것을 받을 때 심사를 하는데 심사기준을 처음에는 루즈하게(많이 나빠도 OK), 점점 까다롭게(탐색 후반부에서는 허용 X)

기체/액체/고체 상변화에서도, 그걸 비유적으로 이야기 할 수 있는  

Loss (책에서는 Energy)  
현재 상황이 좋은가? 에 대한 기준  
얼마나 나쁜가 (클수록 나쁜 것)  
Loss가 낮아야 좋은 것  

교체 확률  
그래프에서, Y축  
1이면 무조건 바꾸겠다  

Delta Energy 평가 결과 = 에너지 E  
I.E. 0~20, 여왕 경로 겹치는 수  

교체 확률, 평가 결과 그래프에 대해,  
평가 결과가 작을 수록 교체 확률이 크다  
평가 결과가 최대까지 가더라도 교체 확률이 존재하긴 하는데 작다  
덜 나쁠수록 더 많은 기회를  

Temperature 온도 (상수)  

자연에서도  
온도가 높다 = 무질서하다 (Like 고체-액체-기체)  
온도를 낮출 수록 안정적인 상태가 된다  

온도가 높다 = 시작 단계  
온도가 낮다 = 끝 단계  

평가 결과가 최대더라도, 온도가 높으면 (즉 시작 단계면)  
교체 확률이 높다  

같은 온도에서는 (다시말해 온도 상관없이는)  
평과 결과가 낮을수록 교체 확률이 높다  

@ 예제, 시험?  
@ 각각 온도 50, 2 라고 가정 (분모)  

### 💫 5차시

---

Adaptive 적응형  
(LOL 적응형 능력치 Adaptive Force)  

Resonance 공명  

모든 물체는 고유한 진동수를 가진다  
진동수 : 1초에 진동하는 수, Hz  

공명 : 같이 운다  
같은 진동수의 물체가 주변에서 진동하면, 함께 진동한다  
진동수가 다르면 공명하지 않는다  

적응형 공명  
-> 기준과 공명하는 것들을 찾아 그룹화 (반복)  
Recommender System  

Adaptive Resonance Theory, ART1 클러스터링  
ART 시리즈의 첫 작  
Unsupervised Learning Algorithm (With Biological Motivations)  
비지도 학습 알고리즘  

Supervise 지도  
(Supervised User)  

지도 학습 - 답이 이미 존재하는, 누가 지도해주는 (Supervised)  
비지도 학습 - 답이 없는 (비정량적인? Like 취향 - 나누는 기준이 정해진 게 없음)  
강화 학습 - 말 그대로  

Clustering Algorithm  
클러스터(덩어리), 군집화 -> 분류, 클래스화(레이블)  
-> Like 하얀건 종이요, 검은건 글씨다  
유사성에 의해 덩어리를 나눈다  

덩어리를 만드는 것 - 비지도 학습  
누가 비슷하다  

분류 - 지도학습  
누가 누구다  

@ 50분 정도 집중력  

사람이 뭔가 배울 떄 이미 알고 있는 것과 비슷한 것을 찾아 연관시키고(덩어리), 만약 그게 없다면 이해를 위한 새로운 생각(덩어리)을 만든다  
에서 모티브를 얻은  

ART1  
뭐가 어떻다 하는 특징 데이터 (테이블)  
1, 0의 개수가 비슷해야 비슷한 데이터  

베타 - 그냥 1.0 몰라도 된다  
d - 전체 물건의 개수  
E - 산 물건  

Create Initial Prototype Vector  
모르기 때문에 임의의 요소 선택 (첫 번째든 랜덤이든)  
P<sub>0</sub> = E<sub>0</sub>  

Proximity 유사  

for each Example Vector  

close to Prototype?  
Proximity Test  
P와E 교집합 (1에 대해서만)/P전체물건 > E산물건(E 1의수)/E전체물건  

@ PDF 8p Eq1 3/4 > 4/8 (오타)  

Vigilance Test? (덩어리로 묶을 지, 한 번 더 평가)  
P와E 교집합/E산개수 \< p (Vigilance Parameter)  

Place Example in Current Prototype Vector (마킹? 라벨링? 덩어리?)  
남은 것들에 대해 새로운 프로토타입을 만들어 반복  
P = P와E 교집합  
1110110  
1110010  
-> 1110010  
덩어리에 크게 의미 없는 데이터를 제거  
(3.4 밑에 Finally 부터 나오는 내용)  

### 💫 6차시

---

K-means Algorithm  
K를 먼저 정하고, (이 데이터에는 K개의 덩어리가 있다고 가정)  
(K를 어떻게 정하냐는 다른 논제)  
(비지도학습 알고리듬이지만, 답이 정해져 있는 것처럼 - K)  

Loop  
K개의 임의의 점들을 기준으로, 가까운 것들을 모아 K개의 덩어리로 만듦  
이후 각 덩어리의 중심으로 K개의 임의의 점들을 재위치  
만약, 이전과 달라진 점이 없다면 End  

실제로는 점이 아니라 테이블  
3차원 이상으로 넘어가면 이해하기 힘듦  

못 찾을 수도 있음  

Using ART1 for Personalization(Recommend System)  
Sum Vector를 이용하여  

### 💫 7차시

---

Ant Algorithm 개미 알고리듬  
개미와 Stigmergy 개미들의 소통방법(냄새/페로몬을 이용한)  

Nest, Food, Obstacle  

개미는 Network을 따라 이동, 냄새가 강한 쪽으로 이동  
컴퓨터 개미는 냄새를 식으로 맡음  
(강의 자료에 있는 식은 오류가 많음)  

타겟 경우의 값 / 현재 위치에서 갈 수 있는 모든 경우의 수 값 합  

타워 t(r, u)  
r, u 사이 페로몬 양  

이타 n(r, u)  
r, u 사이 거리  

만약 페로몬 양이 똑같다면, 거리가 더 짧은 쪽으로  
(때문에 거리는 역수 모양)  

초매개변수, 없어도 되는  

alpha, beta  
alpha, 페로몬 지수  
beta, 거리 지수  
어떤 걸 더 중심적으로 생각하느냐에 따라  

최적의 길을 찾아내는  
변화에도 금방 적응하는  

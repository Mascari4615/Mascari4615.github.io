---
title: "🌑 AI, 로봇 실습 과목"
date: 2023-09-06. 15:06
# last_modified_at: 2023-09-06. 15:06
# last_modified_at: 2023-09-12. 10:15
# last_modified_at: 2023-09-13. 15:01
# last_modified_at: 2023-09-19. 09:58
# last_modified_at: 2023-09-20. 15:09
# last_modified_at: 2023-09-26. 10:01
# last_modified_at: 2023-09-27. 15:06
# last_modified_at: 2023-10-04. 15:01
# last_modified_at: 2023-10-10. 09:44
last_modified_at: 2023-10-11. 15:18
categories: ⭐Computer 🌑Computer-General
---

@ 화 3층, 수 2층  

### 💫 머신러닝 VS 딥러닝

---

머신러닝  
Input -> 특징 추출 -> 분류, 회귀 -> Output  
인공신경망 없이 Classification 분류나 Regression 회귀하는  

Feature Extraction 특징 추출 이후에서야 분류, 회귀가 가능  
-> 때문에 Domain Knowledge 전문 지식이 딥러닝보다 상대적으로 더 요구됨  

딥러닝  
Input -> 특징 추출 + 분류 회귀 -> Output  
인공신경망을 이용한 수치 해석  
인공신경망 내부에서 (자체에서) 분류, 회귀가 가능  

머신러닝보다 상대적으로 좀 더 복잡한 모델  
-> 복잡한 데이터(양, 차원적으로)를 다룰 때, 머신러닝보다 상대적으로 더 정확한 모델을 생성할 가능성이 높음  

인공신경망을 구성할 때 계산되는 Parameter가 굉장히 많고, 결정해야하는 Hyper Parameter가 많기 때문에  
데이터, 모델 사이즈가 클 수록 딥러닝이 더 잘 맞는 경우가 많음  

### 💫 머신러닝, 딥러닝의 세 타입

---

회귀 - 앞으로 어떻게 되나?  

Supervised 지도학습  
Input, Output을 주고 분류, 회귀  

Unsupervised 비지도학습  
Input만 주는  
미지수 2개, 방정식 1개 = 풀 수 없는 문제  
Clustering 군집화  

Reinforcement 강화학습  
Agent가 Action을 Environment에 취했을 때 Reword를 주는..?  

### 💫 머신러닝, 딥러닝

---

Distribution 확률분포가 유사한 데이터를 학습해야한다  

전통적인 방법 : 규칙 만들고 고치고  
그래서 전문 지식이 있어야 하는  

머신러닝 방법 : 지혼자 계속 최적화하는  
데이터만 잘 볼 수 있다면, 전문 지식 없이도  

### 💫 머신러닝

---

KNN Classifier  
K Nearest Neighbors  
근처 K 개의 이웃을 가지고, 내가 누구인지  
때문에 K는 홀수로  
복잡한 디멘션 느리다  

Decision Tree  
알고리즘 성능 측정에 좋다  
데이터를 분개해서 Entropy 복잡도가 가장 낮은 정도의 데이터까지 가도록  
이후 분류, 회귀  
많이 모이면 Random Forest  

Support Vector Machine SVM  
데이터를 분류하는 선 Hyper Line, Hyper Plane  
분류 별로 가장 Hyper Line, Hyper Plane과 가까운 요소와의 거리가 최대가 되도록  
Hyper Line, Hyper Plane을 만드는 Kernel Function -> 어려움  
Cost Function, Object Function, 목적 함수를 만들때는 이정도만 이해해도  

### 💫 딥러닝

---

인공신경망, 체내 신경망을 수학적으로 표시한  
뉴런 -> Node  
Input Layer, Hidden Layer, Output Layer

내가 가지고 있는 데이터에 대해서만 적합한, Overfitting 문제 주의  

Activation Function 활성함수  
자극 받았, 임계치 값 이상을 넘겨주는 역할  
계단식 함수, 0 ~ 1 시그모이드 함수, 렐유 함수 (오버피팅 방지)  

Linear한 알고리즘을 좀 더 Non Linear하게 복잡하게 만들어주는  

### 💫 1차시

---

[Nature of Code](https://natureofcode.com/book/introduction/)  
지능? 뭔지 말할 수는 없지만 느낌은 알고 있다  

### 💫 2차시

---

기호주의 VS 연결주의  
머신러닝 VS 딥러닝  

강인공지능, Strong AI,  
인간 수준의 지능  

인공일반지능, A General I, AGI  
다양한 문제를 해결하고 다향한 지능적 활동을 수핼할 수 있는 능력  
강인공지능, 약인공지능 사이

약인공지능, Weak AI, Narrow AI  
특정한 작업/도메인에서 인간과 유사한 성능을 발휘하는  

튜링 테스트  
Imitation/모방 Game  

에 대한 반박  
중국어방  

에 대한 반박  
System Response  

@ 비욘드 EBS 지능 만들기  

### 💫 3차시

---

AI Application Programming  

Brief 요약  
Manner 방식  
Exhibiting  
Characteristics 특징  
Fraud 사기  
Investigate 조사  

퍼지 추론  
I.E. 카메라 초점  

Lisp -> Python?  

NP-complete  

Simulated Annealing, 모의 담금질 (유사 담금질)  
최적화 -> 검색 -> 모의 담금질  

담금질 : 금속을 가열하고 급냉시켜 경도를 높히는 작업  

고체 -> 액체 -> 기체  
고체 <- 액체 <- 기체  

안정 -> 불안정 (변화 가능한)  

지금보다 더 나은 상태를 요구  
지금 그대로가 아니라 변화가 있어야  
변화가 일어나기 쉬운 상태로  
계속해서 변화만 하면 안됨, 다시 안정한 상태로 만듦  

맹목적 알고리듬  
Greedy Algorithm  
Hill Climbing Algorithm  

임의의 조건/가중치 계산, 결과 저장  
임의의 변형, 새로운 결과 저장  
이전 결과와 새로운 결과 비교  

이를 반복하여 답을 찾는 것 (지금보다 좋은 상황만 찾음)  
-> Greedy Algorithm  

지금 상태가 정말 가장 좋은 상태인가?  
Local M, Global M  

현재 위치에서 한 발자국 씩 옮겨서 더 높은 곳으로 이동  
-> Hill Climbing Algorithm  

평면이나 Local M을 만난다면?  
Local M, Global M  
과적합?  
여러 군데에서 시작하는?  

제일 좋은 곳을 가기위해서는  
좋은 곳만 찾아가지 말고  
욕심을 버리고 아래로 내려가야 한다  
-> 정착을 못함  

시간이 지날수록 조건을 까다롭게  

N Queens  
N x N 보드에서, 서로 영향을 줄 수 없는 체스 여왕 배치 경우의 수  

### 💫 4차시

---

@ 강의실 어딘지 너무 헷갈려~  

초기 soln를 대충 만들어두고  
soln를 평가  
답(최정상)은 모르니까 대강 어느정도 좋다  

핵심 두 가지  

1. 지금보다 더 좋지 않은 솔루션을 찾은 경우에도 이전 것을 버리고 나쁜 것을 받아들일 수 있다는 것
2. 나쁜 것을 받을 때 심사를 하는데 심사기준을 처음에는 루즈하게(많이 나빠도 OK), 점점 까다롭게(탐색 후반부에서는 허용 X)

기체/액체/고체 상변화에서도, 그걸 비유적으로 이야기 할 수 있는  

Loss (책에서는 Energy)  
현재 상황이 좋은가? 에 대한 기준  
얼마나 나쁜가 (클수록 나쁜 것)  
Loss가 낮아야 좋은 것  

교체 확률  
그래프에서, Y축  
1이면 무조건 바꾸겠다  

Delta Energy 평가 결과 = 에너지 E  
I.E. 0~20, 여왕 경로 겹치는 수  

교체 확률, 평가 결과 그래프에 대해,  
평가 결과가 작을 수록 교체 확률이 크다  
평가 결과가 최대까지 가더라도 교체 확률이 존재하긴 하는데 작다  
덜 나쁠수록 더 많은 기회를  

Temperature 온도 (상수)  

자연에서도  
온도가 높다 = 무질서하다 (Like 고체-액체-기체)  
온도를 낮출 수록 안정적인 상태가 된다  

온도가 높다 = 시작 단계  
온도가 낮다 = 끝 단계  

평가 결과가 최대더라도, 온도가 높으면 (즉 시작 단계면)  
교체 확률이 높다  

같은 온도에서는 (다시말해 온도 상관없이는)  
평과 결과가 낮을수록 교체 확률이 높다  

@ 예제, 시험?  
@ 각각 온도 50, 2 라고 가정 (분모)  

### 💫 5차시

---

Adaptive 적응형  
(LOL 적응형 능력치 Adaptive Force)  

Resonance 공명  

모든 물체는 고유한 진동수를 가진다  
진동수 : 1초에 진동하는 수, Hz  

공명 : 같이 운다  
같은 진동수의 물체가 주변에서 진동하면, 함께 진동한다  
진동수가 다르면 공명하지 않는다  

적응형 공명  
-> 기준과 공명하는 것들을 찾아 그룹화 (반복)  
Recommender System  

Adaptive Resonance Theory, ART1 클러스터링  
ART 시리즈의 첫 작  
Unsupervised Learning Algorithm (With Biological Motivations)  
비지도 학습 알고리즘  

Supervise 지도  
(Supervised User)  

지도 학습 - 답이 이미 존재하는, 누가 지도해주는 (Supervised)  
비지도 학습 - 답이 없는 (비정량적인? Like 취향 - 나누는 기준이 정해진 게 없음)  
강화 학습 - 말 그대로  

Clustering Algorithm  
클러스터(덩어리), 군집화 -> 분류, 클래스화(레이블)  
-> Like 하얀건 종이요, 검은건 글씨다  
유사성에 의해 덩어리를 나눈다  

덩어리를 만드는 것 - 비지도 학습  
누가 비슷하다  

분류 - 지도학습  
누가 누구다  

@ 50분 정도 집중력  

사람이 뭔가 배울 떄 이미 알고 있는 것과 비슷한 것을 찾아 연관시키고(덩어리), 만약 그게 없다면 이해를 위한 새로운 생각(덩어리)을 만든다  
에서 모티브를 얻은  

ART1  
뭐가 어떻다 하는 특징 데이터 (테이블)  
1, 0의 개수가 비슷해야 비슷한 데이터  

베타 - 그냥 1.0 몰라도 된다  
d - 전체 물건의 개수  
E - 산 물건  

Create Initial Prototype Vector  
모르기 때문에 임의의 요소 선택 (첫 번째든 랜덤이든)  
P<sub>0</sub> = E<sub>0</sub>  

Proximity 유사  

for each Example Vector  

close to Prototype?  
Proximity Test  
P와E 교집합 (1에 대해서만)/P전체물건 > E산물건(E 1의수)/E전체물건  

@ PDF 8p Eq1 3/4 > 4/8 (오타)  

Vigilance Test? (덩어리로 묶을 지, 한 번 더 평가)  
P와E 교집합/E산개수 \< p (Vigilance Parameter)  

Place Example in Current Prototype Vector (마킹? 라벨링? 덩어리?)  
남은 것들에 대해 새로운 프로토타입을 만들어 반복  
P = P와E 교집합  
1110110  
1110010  
-> 1110010  
덩어리에 크게 의미 없는 데이터를 제거  
(3.4 밑에 Finally 부터 나오는 내용)  

### 💫 6차시

---

K-means Algorithm  
K를 먼저 정하고, (이 데이터에는 K개의 덩어리가 있다고 가정)  
(K를 어떻게 정하냐는 다른 논제)  
(비지도학습 알고리듬이지만, 답이 정해져 있는 것처럼 - K)  

Loop  
K개의 임의의 점들을 기준으로, 가까운 것들을 모아 K개의 덩어리로 만듦  
이후 각 덩어리의 중심으로 K개의 임의의 점들을 재위치  
만약, 이전과 달라진 점이 없다면 End  

실제로는 점이 아니라 테이블  
3차원 이상으로 넘어가면 이해하기 힘듦  

못 찾을 수도 있음  

Using ART1 for Personalization(Recommend System)  
Sum Vector를 이용하여  

### 💫 7차시

---

Ant Algorithm 개미 알고리듬  
개미와 Stigmergy 개미들의 소통방법(냄새/페로몬을 이용한)  

Nest, Food, Obstacle  

개미는 Network을 따라 이동, 냄새가 강한 쪽으로 이동  
컴퓨터 개미는 냄새를 식으로 맡음  
(강의 자료에 있는 식은 오류가 많음)  

타겟 경우의 값 / 현재 위치에서 갈 수 있는 모든 경우의 수 값 합  

타워 t(r, u)  
r, u 사이 페로몬 양  

이타 n(r, u)  
r, u 사이 거리  

만약 페로몬 양이 똑같다면, 거리가 더 짧은 쪽으로  
(때문에 거리는 역수 모양)  

초매개변수, 없어도 되는  

alpha, beta  
alpha, 페로몬 지수  
beta, 거리 지수  
어떤 걸 더 중심적으로 생각하느냐에 따라  

최적의 길을 찾아내는  
변화에도 금방 적응하는  

### 💫 8차시

---

TSP Traveling Salesman Problem  
= 해밀턴 패턴, 모든 정점을 중복없이 한 번씩만 방문  

### 💫 10차시

---

신경망과 역전파 알고리듬  
뉴런과 시냅스  

배우는 것 (구조, 학습 알고리듬)  
학습 알고리듬 : Error Backpropagation Learning Algorithm 역전파 학습 알고리듬을 통한  
Architectures 구조 : Feed-Forward 전진 전파 / Multi-Layer Neural Network 다층 신경망(뉴런적인) 네트워크  

역전파 알고리듬이 신경망 연구에 부활을 일으켰다?  
Resurgence 부활  

Topologies 이상 = Architectures 구조  

AI 매개변수가 ~개다 = 시냅스가 ~개다  

@ ⭐ 뉴런 - 입력은 여러 개, 출력은 한 개 (갈라지긴 하지만 값이 하나라는 뜻)  

시냅스 Like 수도꼭지  
신호량 통제/조절  

인공 뉴런  
가중치 W Weight == 시냅스  

1. 입력들을 각가의 가중치를 곱해 X를 구하고 더함 Weighted Sum
2. Activation Function 활성 함수를 통해 최종 값 계산 (X가 겁나 크니까 작게 찌그러뜨리기/조절하기)

뉴럴 네트워크, 다층 신경망  
중간층(구 은닉층)  

입력층의 뉴런은 모양이 다르다!?  
모든 뉴런은 뭔가 입력을 받아서 계산을 하고 뿌리는데,  
입력층 뉴런은 그냥 입력을 받아서 뿌리기만 함  
반대로 보면 입력을 받을 때 다 가중치를 곱한 값을 가져오는데, 입력층은 그런거 없이 그냥 가져옴  
그래서 엄밀히 말하면 입력층은 뉴런이 아님  

Feed-Forward  
입력을 계산해서 출력을 앞으로 앞으로 보낸다  

레이어 256개? 몇 백개?  
뇌도 레이어가 나뉜다 (뉴런이 집중되어 있거나 좀 옅거나)  

RNN, 순환 신경망은  
한 층에서 다음 층으로, 뉴런이 출력을 할 때  
자기 자신에게도 출력값을 입력함 (Feedback)  

i번째 뉴런과 j번째 뉴런을 잇는 가중치 Wij  

무튼 사용하는 입장에서는 뉴럴 네트워크 안의 과정/원리를 모른채  
I.E. 대화 인공지능에 질문을 하면, 뭔가 처리되고, 답변이 옴  

우리가 원하는 값을 찾기 위해서 직접 가중치를 조정해야 하는 거면 안쓰지  
우리는 입력 출력 페어만 전달하고, 그 가중치를 찾는 과정을 AI가  

오류 역전파 학습 알고리듬  
오류? 우리가 AI에게 준 입력 출력 페어랑 출력이 다른 거  
그걸 이용해서 다시 가중치를 수정하는 알고리듬  

중간-출력층 사이의 가중치 조정  
Wij = Wjk + △Wjk  
△델타Wjk를 아는 값과 (이상 - 에러 오차)를 이용하여 계산  

입력-중간층 사이의 가중치 조정  
Wij = Wjk + △Wjk  
△델타Wjk를 아는 값과 (중간-출력층 사이의 가중치 조정 과정에서 구한 값)을 이용하여 계산  

역전파  
-> 입력-중간층 사이 가중치를 고치기 위해서, 중간-출력층 사이 가중치를 먼저 고치고 나온 값을 이용  

여기서 문제  
여러 층을 거쳐 옮겨오다보면 제대로 동작 안함?  

그래서 그 문제를 해결하기 위해 나온게 딥러닝  

알고리듬을 보면 그냥 더하기만 있음 (곱하기도 더하기)  
간단한 계산, 그래서 한 번에 많은 단순 계산을 할 수 있는 GPU를 사용  

답을 아는 경우  
답을 모르면 강화학습, 비지도 학습?  

### 💫 11차시

---

@ 이러한 신경망 구조가 어떻게 되냐?  

@ 다음 층의 뉴런과 모두 연결된다
@ 맨 위, 맨 아래 뉴런 빼고 모두 생략해서 그리기  

Feed-Foward -> Back Backpropagation  
